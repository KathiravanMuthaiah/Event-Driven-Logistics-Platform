# üìò **Application Requirements Document**

------

## üéØ **Project Name**

**Event-Driven Logistics Platform**

------

## üü¢ **Objective**

This project demonstrates how a modern manufacturing company (**Bauto**) can:

- Ingest production and sensor events
- Process and enrich data streams in real time
- Persist events for auditing and reporting
- Integrate with external systems using decoupled consumers

It serves as a **learning platform** to teach developers:

- Event-driven architecture concepts
- Kafka and Kafka Streams
- MQTT ingestion
- Microservices with Quarkus
- PostgreSQL persistence
- Monitoring with Prometheus

------

## üõ†Ô∏è **High-Level Functional Overview**

The platform consists of **seven core components**:

------

### üîπ 1Ô∏è‚É£ Inbound Order Producer

- A microservice exposes an HTTP REST API to receive *material call-off* orders.
- Each received order is published to Kafka (`call-off-topic`) in JSON format.

------

### üîπ 2Ô∏è‚É£ MQTT Ingestor

- A microservice subscribes to an MQTT broker (`sensors/#`) to collect real-time production or environmental sensor data.
- Each incoming MQTT message is published to Kafka (`sensor-topic`).

------

### üîπ 3Ô∏è‚É£ Kafka Streams Processor

- This service consumes both `call-off-topic` and `sensor-topic`.
- It performs:
  - Event enrichment
  - Transformation
  - Joining records into a unified event
- It publishes the enriched records to `unified-topic`.

------

### üîπ 4Ô∏è‚É£ PostgreSQL Writer

- Capture sensor-topic and call-off-topic data and post into data base for persistence. this is extended listener to capture all data in DB. not the main logic. ( This section is development completed for basic purpose)
- This service subscribes to `unified-topic`.
- It persists all events into a PostgreSQL database table (`logistics_events`) for traceability and reporting.

------

### üîπ 5Ô∏è‚É£ Mock SAP Integration Service

- A microservice simulates an external SAP system.
- It subscribes to relevant Kafka topics or exposes REST endpoints to receive event notifications.

------

### üîπ 6Ô∏è‚É£ Mock Supply Control Service

- A simulated external service that represents a supply control system.
- It receives events either via Kafka consumer or REST endpoint.

------

### üîπ 7Ô∏è‚É£ Mock Supplier EDI Service

- A dummy REST service to emulate an EDI integration with suppliers.
- Optionally subscribes to Kafka topics for automated order updates.

------

### üîπ 8Ô∏è‚É£ Monitoring API

- A microservice exposes REST APIs to:
  - Query persisted events in PostgreSQL.
  - Return metrics (Micrometer Prometheus format) for observability.

------

## üü¢ **Key Use Cases**

**Use Case 1: Ingest Call-Off Orders**

- An operator or automated system posts JSON payloads to the HTTP API.
- The producer service forwards these events to Kafka.

------

**Use Case 2: Stream Sensor Data**

- The MQTT broker streams sensor messages.
- The MQTT ingestor picks them up and produces Kafka events.

------

**Use Case 3: Merge and Enrich Data Streams**

- The Kafka Streams processor:
  - Joins call-off events with sensor data.
  - Creates a unified enriched event.

------

**Use Case 4: Persist and Audit**

- The PostgreSQL writer persists all unified events for compliance and auditing.

------

**Use Case 5: Integrate with External Systems**

- Mock SAP, Supply Control, and Supplier EDI services consume relevant events.
- These simulate real integrations with external platforms.

------

**Use Case 6: Monitoring and Metrics**

- Developers and operators can:
  - Query persisted data.
  - View Prometheus metrics via Micrometer.

------



**platform architecture** should demonstrate:

```mermaid
flowchart TD
    RESTAPI[Inbound Order Producer] --> KafkaCallOff[(call-off-topic)]
    MQTTClient[MQTT Ingestor] --> KafkaSensor[(sensor-topic)]
    KafkaCallOff --> StreamProc[Kafka Streams Processor]
    KafkaSensor --> StreamProc
    StreamProc --> KafkaUnified[(unified-topic)]

    KafkaCallOff --> PGWriter[PostgreSQL Writer]
    KafkaSensor --> PGWriter

    KafkaUnified --> PGWriter[PostgreSQL Writer]
    KafkaUnified --> SAP[Mock SAP Service]
    KafkaUnified --> EDI[Mock Supplier EDI]
    KafkaUnified --> SupplyControl[Mock Supply Control]

    PGWriter --> PostgreSQL[(logistics DB)]
    PostgreSQL --> MonitoringAPI[Monitoring API]
```



## üü¢ **Non-Functional Requirements**

| Requirement       | Details                                         |
| ----------------- | ----------------------------------------------- |
| **Performance**   | Handle ~50‚Äì100 events/sec for simulation        |
| **Resilience**    | Kafka-based recovery and replay support         |
| **Observability** | All services expose `/q/metrics` for Prometheus |
| **Scalability**   | Services can scale independently                |
| **Simplicity**    | No security/authentication initially            |
| **Portability**   | Runs via Docker Compose and optionally Minikube |



------

## üü¢ **Data Flow Summary**

1Ô∏è‚É£ REST call-off orders ‚Üí Kafka `call-off-topic`
 2Ô∏è‚É£ MQTT sensor data ‚Üí Kafka `sensor-topic`
 3Ô∏è‚É£ Kafka Streams merge ‚Üí `unified-topic`
 4Ô∏è‚É£ PostgreSQL Writer persists events
 5Ô∏è‚É£ Mock services consume events
 6Ô∏è‚É£ Monitoring API provides event queries and metrics

------

## üü¢ **Event Formats**

‚úÖ All messages exchanged will use **JSON**.

Example Call-Off Event:

```json
{
  "call_off_id": "CO123456",
  "supplier_id": "SUP789",
  "part_number": "PN-001-A",
  "quantity": 500,
  "destination_location": "WH-ZONE-3",
  "planned_delivery_time": "2025-07-16T15:30:00Z",
  "status": "SCHEDULED"
}
```

Example Sensor Event:

```json
{"sensorId":"abc124","partNumber":"PN-01","location":"ZONE-A","temperature":72.5,"humidity":55.0,"timestamp":"2025-07-17T13:00:00"}
```

Example Unified Event:

```structured text
yet to design on how to unify the sensor data and call-off event data.
```

------

## üü¢ **Dependencies**

‚úÖ Docker Compose for:

- Kafka
- Zookeeper
- MQTT
- PostgreSQL

‚úÖ GraalVM JDK 17 for Quarkus apps

‚úÖ Prometheus-compatible metrics endpoint (`/q/metrics`) in every service

------

## üü¢ **Scope Exclusions**

- No production-grade security (SSL/TLS, ACLs)
- No Avro/Protobuf schemas
- No external authentication

------

## üü¢ **Project Outcomes**

‚úÖ Developers will learn:

- Kafka Producer/Consumer development
- Kafka Streams transformations
- MQTT ingestion flows
- Event persistence patterns
- Microservice observability

‚úÖ This project will serve as:

- A reference architecture
- A training lab
- A demonstration platform for event-driven supply chain flows

------

‚úÖ **End of Document**